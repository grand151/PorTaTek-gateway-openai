# Emulator API OpenAI z uÅ¼yciem darmowych modeli

Ten projekt to gateway (proxy), ktÃ³ry emuluje interfejs API OpenAI, przekierowujÄ…c zapytania do darmowych modeli dostÄ™pnych przez OpenRouter, gÅ‚Ã³wnie Mistral Small.

## Funkcje

- ğŸ”„ PeÅ‚na emulacja API OpenAI (drop-in replacement)
- ğŸ†“ Wykorzystanie darmowych modeli OpenRouter
- ğŸ—ºï¸ Automatyczne mapowanie modeli GPT na darmowe alternatywy
- ğŸ”„ Automatyczny retry w przypadku bÅ‚Ä™dÃ³w
- ğŸ”€ Fallback do alternatywnych modeli w przypadku awarii
- ğŸ’¾ Cachowanie odpowiedzi dla oszczÄ™dnoÅ›ci czasu i zasobÃ³w
- ğŸ–¼ï¸ ObsÅ‚uga modeli multimodalnych (tekst + obrazy)

## Mapowanie modeli

| Model OpenAI | Model OpenRouter |
|--------------|------------------|
| gpt-3.5-turbo | mistralai/mistral-small-3.1-24b-instruct:free |
| gpt-4 | mistralai/mistral-small-3.1-24b-instruct:free |
| gpt-4-vision | qwen/qwen2.5-vl-32b-instruct:free |
| text-embedding-ada-002 | mistralai/mistral-embed:free |

## Wymagania

- Node.js 14+
- npm lub yarn

## Instalacja

```bash
# Klonowanie repozytorium
git clone <repo-url>
cd openai-gateway

# Instalacja zaleÅ¼noÅ›ci
npm install

# Konfiguracja zmiennych Å›rodowiskowych
cp .env.example .env
# Edytuj plik .env z twoimi ustawieniami
```

## Uruchomienie

```bash
# Standardowe uruchomienie
npm start

# Tryb deweloperski z automatycznym restartem
npm run dev
```

Gateway bÄ™dzie dostÄ™pny pod adresem `http://localhost:8787`.

## UÅ¼ycie

MoÅ¼esz uÅ¼ywaÄ‡ tego gateway dokÅ‚adnie tak samo jak normalnego API OpenAI:

### Curl

```bash
curl -X POST "http://localhost:8787/v1/chat/completions" \
  -H "Content-Type: application/json" \
  -d '{
    "model": "gpt-3.5-turbo",
    "messages": [
        {"role": "user", "content": "Twoje pytanie"}
    ]
  }'
```

### Python (OpenAI SDK)

```python
from openai import OpenAI

# Inicjalizacja klienta z nowym base URL
client = OpenAI(
    base_url="http://localhost:8787/v1",
    api_key="dowolny-string"  # klucz nie jest sprawdzany
)

# UÅ¼ycie dokÅ‚adnie jak z OpenAI
response = client.chat.completions.create(
    model="gpt-3.5-turbo",
    messages=[
        {"role": "user", "content": "Twoje pytanie"}
    ]
)

print(response.choices[0].message.content)
```

### JavaScript/TypeScript

```javascript
import OpenAI from "openai";

const client = new OpenAI({
  baseURL: "http://localhost:8787/v1",
  apiKey: "dowolny-string" // klucz nie jest sprawdzany
});

const response = await client.chat.completions.create({
  model: "gpt-3.5-turbo",
  messages: [
    { role: "user", content: "Twoje pytanie" }
  ]
});

console.log(response.choices[0].message.content);
```

## DostÄ™pne endpointy

- `/v1/chat/completions` - generowanie odpowiedzi czatu
- `/v1/embeddings` - generowanie embeddingÃ³w
- `/v1/models` - lista dostÄ™pnych modeli
- `/health` - sprawdzenie statusu serwera
- `/` - informacje o gateway

## Docker

```bash
# Budowanie obrazu
docker build -t openai-gateway .

# Uruchomienie
docker run -p 8787:8787 --env-file .env openai-gateway
```

MoÅ¼esz teÅ¼ uÅ¼yÄ‡ docker-compose:

```bash
docker-compose up -d
```

## Zmienne Å›rodowiskowe

| Zmienna | Opis | DomyÅ›lna wartoÅ›Ä‡ |
|---------|------|------------------|
| PORT | Port na ktÃ³rym dziaÅ‚a serwer | 8787 |
| OPENROUTER_API_KEY | Klucz API do OpenRouter | (wymagany) |
| CACHE_TTL | Czas Å¼ycia cache w milisekundach | 3600000 (1h) |
| MAX_RETRIES | Maksymalna liczba ponownych prÃ³b | 3 |
| RETRY_DELAY | OpÃ³Åºnienie miÄ™dzy prÃ³bami (ms) | 1000 |

## Limity i ograniczenia

- Darmowe modele mogÄ… byÄ‡ wolniejsze niÅ¼ oryginalne modele OpenAI
- NiektÃ³re zaawansowane funkcje OpenAI mogÄ… nie dziaÅ‚aÄ‡
- DostÄ™pnoÅ›Ä‡ zaleÅ¼y od usÅ‚ug OpenRouter

## RozwiÄ…zywanie problemÃ³w

1. **Timeout** - ZwiÄ™ksz MAX_RETRIES w pliku .env
2. **BÅ‚Ä™dy modelu** - SprawdÅº logi, zweryfikuj poprawnoÅ›Ä‡ klucza API
3. **Problemy z wydajnoÅ›ciÄ…** - Dostosuj ustawienia cache i retry

## Licencja

MIT
